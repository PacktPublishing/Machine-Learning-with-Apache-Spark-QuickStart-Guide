{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) Import the required Python dependencies\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.sql.types import DoubleType, IntegerType, StringType\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import OneHotEncoderEstimator\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2) Instantiate a Spark Context\n",
    "conf = SparkConf().setMaster(\"spark://192.168.56.10:7077\").setAppName(\"CART - Congressional Voting\")\n",
    "sc = SparkContext(conf=conf)\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+--------------------------+---------------------------------+--------------------+---------------+---------------------------+-----------------------+-------------------------+----------+-----------+----------------------------+------------------+----------------------+-----+-----------------+--------------------------------------+\n",
      "|     party|handicapped_infants|water_project_cost_sharing|adoption_of_the_budget_resolution|physician_fee_freeze|el_salvador_aid|religious_groups_in_schools|anti_satellite_test_ban|aid_to_nicaraguan_contras|mx_missile|immigration|synfuels_corporation_cutback|education_spending|superfund_right_to_sue|crime|duty_free_exports|export_administration_act_south_africa|\n",
      "+----------+-------------------+--------------------------+---------------------------------+--------------------+---------------+---------------------------+-----------------------+-------------------------+----------+-----------+----------------------------+------------------+----------------------+-----+-----------------+--------------------------------------+\n",
      "|republican|                  n|                         y|                                n|                   y|              y|                          y|                      n|                        n|         n|          y|                           ?|                 y|                     y|    y|                n|                                     y|\n",
      "|republican|                  n|                         y|                                n|                   y|              y|                          y|                      n|                        n|         n|          n|                           n|                 y|                     y|    y|                n|                                     ?|\n",
      "+----------+-------------------+--------------------------+---------------------------------+--------------------+---------------+---------------------------+-----------------------+-------------------------+----------+-----------+----------------------------+------------------+----------------------+-----+-----------------+--------------------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (3) Load the Congressional Voting dataset (data/congressional-voting-data/house-votes-84.csv) into a Spark DataFrame\n",
    "schema = StructType([\n",
    "    StructField(\"party\", StringType()),\n",
    "    StructField(\"handicapped_infants\", StringType()),\n",
    "    StructField(\"water_project_cost_sharing\", StringType()),\n",
    "    StructField(\"adoption_of_the_budget_resolution\", StringType()),\n",
    "    StructField(\"physician_fee_freeze\", StringType()),\n",
    "    StructField(\"el_salvador_aid\", StringType()),\n",
    "    StructField(\"religious_groups_in_schools\", StringType()),\n",
    "    StructField(\"anti_satellite_test_ban\", StringType()),\n",
    "    StructField(\"aid_to_nicaraguan_contras\", StringType()),\n",
    "    StructField(\"mx_missile\", StringType()),\n",
    "    StructField(\"immigration\", StringType()),\n",
    "    StructField(\"synfuels_corporation_cutback\", StringType()),\n",
    "    StructField(\"education_spending\", StringType()),\n",
    "    StructField(\"superfund_right_to_sue\", StringType()),\n",
    "    StructField(\"crime\", StringType()),\n",
    "    StructField(\"duty_free_exports\", StringType()),\n",
    "    StructField(\"export_administration_act_south_africa\", StringType())\n",
    "])\n",
    "\n",
    "congressional_voting_df = sqlContext.read.format('com.databricks.spark.csv').schema(schema).options(header = 'false', inferschema = 'false').load('/data/workspaces/jillur.quddus/jupyter/notebooks/Machine-Learning-with-Apache-Spark-QuickStart-Guide/chapter04/data/congressional-voting-data/house-votes-84.data')\n",
    "congressional_voting_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (4) Index the relevant categorical and label variables using a Pipeline of stages\n",
    "categorical_columns = ['handicapped_infants', 'water_project_cost_sharing', 'adoption_of_the_budget_resolution', 'physician_fee_freeze', 'el_salvador_aid', 'religious_groups_in_schools', 'anti_satellite_test_ban', 'aid_to_nicaraguan_contras', 'mx_missile', 'immigration', 'synfuels_corporation_cutback', 'education_spending', 'superfund_right_to_sue', 'crime', 'duty_free_exports', 'export_administration_act_south_africa']\n",
    "pipeline_stages = []\n",
    "for categorial_column in categorical_columns:\n",
    "    string_indexer = StringIndexer(inputCol = categorial_column, outputCol = categorial_column + 'Index')\n",
    "    encoder = OneHotEncoderEstimator(inputCols = [string_indexer.getOutputCol()], outputCols=[categorial_column + \"classVec\"])\n",
    "    pipeline_stages += [string_indexer, encoder]\n",
    "    \n",
    "label_string_idx = StringIndexer(inputCol = 'party', outputCol = 'label')\n",
    "pipeline_stages += [label_string_idx]\n",
    "vector_assembler_inputs = [c + \"classVec\" for c in categorical_columns]\n",
    "vector_assembler = VectorAssembler(inputCols = vector_assembler_inputs, outputCol = \"features\")\n",
    "pipeline_stages += [vector_assembler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>features</th>\n",
       "      <td>(1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, ...</td>\n",
       "      <td>(1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, ...</td>\n",
       "      <td>(0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>(1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>party</th>\n",
       "      <td>republican</td>\n",
       "      <td>republican</td>\n",
       "      <td>democrat</td>\n",
       "      <td>democrat</td>\n",
       "      <td>democrat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          0  \\\n",
       "features  (1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, ...   \n",
       "label                                                     1   \n",
       "party                                            republican   \n",
       "\n",
       "                                                          1  \\\n",
       "features  (1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, ...   \n",
       "label                                                     1   \n",
       "party                                            republican   \n",
       "\n",
       "                                                          2  \\\n",
       "features  (0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, ...   \n",
       "label                                                     0   \n",
       "party                                              democrat   \n",
       "\n",
       "                                                          3  \\\n",
       "features  (1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, ...   \n",
       "label                                                     0   \n",
       "party                                              democrat   \n",
       "\n",
       "                                                          4  \n",
       "features  (0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, ...  \n",
       "label                                                     0  \n",
       "party                                              democrat  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (5) Generate Input Feature Vectors from the Raw Spark DataFrame by executing the previously constructed Pipeline\n",
    "pipeline = Pipeline(stages = pipeline_stages)\n",
    "pipeline_model = pipeline.fit(congressional_voting_df)\n",
    "label_column = 'label'\n",
    "congressional_voting_features_df = pipeline_model.transform(congressional_voting_df).select(['features', label_column, 'party'])\n",
    "pd.DataFrame(congressional_voting_features_df.take(5), columns=congressional_voting_features_df.columns).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(322, 113)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (6) Split the Raw Features and Labelled DataFrame into a Training DataFrame and a Test DataFrame\n",
    "train_df, test_df = congressional_voting_features_df.randomSplit([0.75, 0.25], seed=12345)\n",
    "train_df.count(), test_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (7) Train a Classification Tree Model on the Training DataFrame\n",
    "decision_tree = DecisionTreeClassifier(featuresCol = 'features', labelCol = label_column)\n",
    "decision_tree_model = decision_tree.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST DATASET PREDICTIONS AGAINST ACTUAL LABEL: \n",
      "+-----------+-------------+----------+-----+--------------------+\n",
      "|probability|rawPrediction|prediction|label|            features|\n",
      "+-----------+-------------+----------+-----+--------------------+\n",
      "|  [1.0,0.0]|  [167.0,0.0]|       0.0|  0.0|(32,[0,2,4,6,8,10...|\n",
      "|  [1.0,0.0]|  [167.0,0.0]|       0.0|  0.0|(32,[0,2,4,6,8,12...|\n",
      "|  [1.0,0.0]|  [167.0,0.0]|       0.0|  0.0|(32,[0,2,4,6,9,10...|\n",
      "|  [1.0,0.0]|  [167.0,0.0]|       0.0|  0.0|(32,[0,2,4,6,9,10...|\n",
      "|  [1.0,0.0]|  [167.0,0.0]|       0.0|  0.0|(32,[0,2,4,6,9,10...|\n",
      "|  [1.0,0.0]|  [167.0,0.0]|       0.0|  0.0|(32,[0,2,4,6,9,10...|\n",
      "|  [0.0,1.0]|   [0.0,96.0]|       1.0|  0.0|(32,[0,2,4,7,8,10...|\n",
      "|  [0.0,1.0]|   [0.0,96.0]|       1.0|  0.0|(32,[0,2,4,7,8,10...|\n",
      "|  [1.0,0.0]|   [12.0,0.0]|       0.0|  0.0|(32,[0,2,5,6,8,10...|\n",
      "|  [0.0,1.0]|   [0.0,96.0]|       1.0|  1.0|(32,[0,2,5,7,8,10...|\n",
      "|  [0.0,1.0]|   [0.0,96.0]|       1.0|  1.0|(32,[0,2,5,7,8,10...|\n",
      "|  [0.0,1.0]|   [0.0,96.0]|       1.0|  1.0|(32,[0,2,5,7,8,10...|\n",
      "|  [0.0,1.0]|   [0.0,96.0]|       1.0|  1.0|(32,[0,2,5,7,8,10...|\n",
      "|  [0.0,1.0]|   [0.0,13.0]|       1.0|  1.0|(32,[0,2,5,7,8,10...|\n",
      "|  [0.0,1.0]|   [0.0,13.0]|       1.0|  0.0|(32,[0,2,5,7,8,10...|\n",
      "|  [0.0,1.0]|   [0.0,96.0]|       1.0|  1.0|(32,[0,2,5,7,8,10...|\n",
      "|  [0.0,1.0]|   [0.0,96.0]|       1.0|  1.0|(32,[0,2,5,7,8,10...|\n",
      "|  [0.0,1.0]|   [0.0,96.0]|       1.0|  1.0|(32,[0,2,5,7,8,10...|\n",
      "|  [0.0,1.0]|   [0.0,96.0]|       1.0|  1.0|(32,[0,2,5,7,8,10...|\n",
      "|  [0.0,1.0]|   [0.0,96.0]|       1.0|  1.0|(32,[0,2,5,7,8,10...|\n",
      "+-----------+-------------+----------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (8) Apply the Trained Classification Tree Model to the Test DataFrame to make predictions\n",
    "test_decision_tree_predictions_df = decision_tree_model.transform(test_df)\n",
    "print(\"TEST DATASET PREDICTIONS AGAINST ACTUAL LABEL: \")\n",
    "test_decision_tree_predictions_df.select(\"probability\", \"rawPrediction\", \"prediction\", label_column, \"features\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area Under ROC Curve on Test Data = 0.909553\n"
     ]
    }
   ],
   "source": [
    "# (9) Evaluate the performance of our Classification Tree Model on the Test DataFrame using Area under a ROC curve\n",
    "evaluator_roc_area = BinaryClassificationEvaluator(rawPredictionCol = \"rawPrediction\", labelCol = label_column, metricName = \"areaUnderROC\")\n",
    "print(\"Area Under ROC Curve on Test Data = %g\" % evaluator_roc_area.evaluate(test_decision_tree_predictions_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassificationModel (uid=DecisionTreeClassifier_4342b3d31685b6648513) of depth 5 with 31 nodes\n",
      "  If (feature 7 in {0.0})\n",
      "   If (feature 6 in {1.0})\n",
      "    If (feature 5 in {0.0})\n",
      "     Predict: 0.0\n",
      "    Else (feature 5 not in {0.0})\n",
      "     If (feature 11 in {0.0})\n",
      "      Predict: 0.0\n",
      "     Else (feature 11 not in {0.0})\n",
      "      If (feature 2 in {1.0})\n",
      "       Predict: 0.0\n",
      "      Else (feature 2 not in {1.0})\n",
      "       Predict: 1.0\n",
      "   Else (feature 6 not in {1.0})\n",
      "    If (feature 20 in {0.0})\n",
      "     If (feature 10 in {1.0})\n",
      "      Predict: 0.0\n",
      "     Else (feature 10 not in {1.0})\n",
      "      If (feature 1 in {1.0})\n",
      "       Predict: 0.0\n",
      "      Else (feature 1 not in {1.0})\n",
      "       Predict: 0.0\n",
      "    Else (feature 20 not in {0.0})\n",
      "     Predict: 1.0\n",
      "  Else (feature 7 not in {0.0})\n",
      "   If (feature 31 in {1.0})\n",
      "    If (feature 16 in {1.0})\n",
      "     Predict: 0.0\n",
      "    Else (feature 16 not in {1.0})\n",
      "     If (feature 4 in {1.0})\n",
      "      If (feature 12 in {0.0})\n",
      "       Predict: 0.0\n",
      "      Else (feature 12 not in {0.0})\n",
      "       Predict: 1.0\n",
      "     Else (feature 4 not in {1.0})\n",
      "      If (feature 0 in {0.0})\n",
      "       Predict: 0.0\n",
      "      Else (feature 0 not in {0.0})\n",
      "       Predict: 1.0\n",
      "   Else (feature 31 not in {1.0})\n",
      "    If (feature 22 in {1.0})\n",
      "     If (feature 30 in {0.0})\n",
      "      Predict: 0.0\n",
      "     Else (feature 30 not in {0.0})\n",
      "      Predict: 1.0\n",
      "    Else (feature 22 not in {1.0})\n",
      "     Predict: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (10) Visualise the Classification Tree\n",
    "print(str(decision_tree_model.toDebugString))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (11) Train a Random Forest Classifier Model on the Training DataFrame\n",
    "random_forest = RandomForestClassifier(featuresCol = 'features', labelCol = label_column)\n",
    "random_forest_model = random_forest.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST DATASET PREDICTIONS AGAINST ACTUAL LABEL: \n",
      "+--------------------+--------------------+----------+-----+--------------------+\n",
      "|         probability|       rawPrediction|prediction|label|            features|\n",
      "+--------------------+--------------------+----------+-----+--------------------+\n",
      "|[0.99444444444444...|[19.8888888888888...|       0.0|  0.0|(32,[0,2,4,6,8,10...|\n",
      "|         [0.95,0.05]|          [19.0,1.0]|       0.0|  0.0|(32,[0,2,4,6,8,12...|\n",
      "|[0.99166666666666...|[19.8333333333333...|       0.0|  0.0|(32,[0,2,4,6,9,10...|\n",
      "|[0.97142857142857...|[19.4285714285714...|       0.0|  0.0|(32,[0,2,4,6,9,10...|\n",
      "|           [1.0,0.0]|          [20.0,0.0]|       0.0|  0.0|(32,[0,2,4,6,9,10...|\n",
      "|[0.99166666666666...|[19.8333333333333...|       0.0|  0.0|(32,[0,2,4,6,9,10...|\n",
      "|[0.26964285714285...|[5.39285714285714...|       1.0|  0.0|(32,[0,2,4,7,8,10...|\n",
      "|[0.42361111111111...|[8.47222222222222...|       1.0|  0.0|(32,[0,2,4,7,8,10...|\n",
      "|[0.90348837209302...|[18.0697674418604...|       0.0|  0.0|(32,[0,2,5,6,8,10...|\n",
      "|[0.03757928118393...|[0.75158562367864...|       1.0|  1.0|(32,[0,2,5,7,8,10...|\n",
      "|[0.01257928118393...|[0.25158562367864...|       1.0|  1.0|(32,[0,2,5,7,8,10...|\n",
      "|[0.01257928118393...|[0.25158562367864...|       1.0|  1.0|(32,[0,2,5,7,8,10...|\n",
      "|[0.00611995104039...|[0.12239902080783...|       1.0|  1.0|(32,[0,2,5,7,8,10...|\n",
      "|[0.09618678479143...|[1.92373569582871...|       1.0|  1.0|(32,[0,2,5,7,8,10...|\n",
      "|[0.09618678479143...|[1.92373569582871...|       1.0|  0.0|(32,[0,2,5,7,8,10...|\n",
      "|[0.01436499546964...|[0.28729990939293...|       1.0|  1.0|(32,[0,2,5,7,8,10...|\n",
      "|[0.01436499546964...|[0.28729990939293...|       1.0|  1.0|(32,[0,2,5,7,8,10...|\n",
      "|[0.01436499546964...|[0.28729990939293...|       1.0|  1.0|(32,[0,2,5,7,8,10...|\n",
      "|[0.01436499546964...|[0.28729990939293...|       1.0|  1.0|(32,[0,2,5,7,8,10...|\n",
      "|[0.00527408637873...|[0.10548172757475...|       1.0|  1.0|(32,[0,2,5,7,8,10...|\n",
      "+--------------------+--------------------+----------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (12) Apply the Trained Random Forest Classifier Model to the Test DataFrame to make predictions\n",
    "test_random_forest_predictions_df = random_forest_model.transform(test_df)\n",
    "print(\"TEST DATASET PREDICTIONS AGAINST ACTUAL LABEL: \")\n",
    "test_random_forest_predictions_df.select(\"probability\", \"rawPrediction\", \"prediction\", label_column, \"features\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area Under ROC Curve on Test Data = 0.974593\n"
     ]
    }
   ],
   "source": [
    "# (13) Evaluate the performance of our Random Forest Classifier Model on the Test DataFrame using Area under a ROC curve\n",
    "evaluator_rf_roc_area = BinaryClassificationEvaluator(rawPredictionCol = \"rawPrediction\", labelCol = label_column, metricName = \"areaUnderROC\")\n",
    "print(\"Area Under ROC Curve on Test Data = %g\" % evaluator_rf_roc_area.evaluate(test_random_forest_predictions_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (14) Stop the Spark Context\n",
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
