{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) Import the required Python dependencies\n",
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2) Instantiate a Spark Context\n",
    "conf = SparkConf().setMaster(\"spark://192.168.56.10:7077\").setAppName(\"Multilayer Perceptron - OCR\")\n",
    "sc = SparkContext(conf=conf)\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------------------------------------------------------------------+\n",
      "|label|features                                                              |\n",
      "+-----+----------------------------------------------------------------------+\n",
      "|19   |[2.0,8.0,3.0,5.0,1.0,8.0,13.0,0.0,6.0,6.0,10.0,8.0,0.0,8.0,0.0,8.0]   |\n",
      "|8    |[5.0,12.0,3.0,7.0,2.0,10.0,5.0,5.0,4.0,13.0,3.0,9.0,2.0,8.0,4.0,10.0] |\n",
      "|3    |[4.0,11.0,6.0,8.0,6.0,10.0,6.0,2.0,6.0,10.0,3.0,7.0,3.0,7.0,3.0,9.0]  |\n",
      "|13   |[7.0,11.0,6.0,6.0,3.0,5.0,9.0,4.0,6.0,4.0,4.0,10.0,6.0,10.0,2.0,8.0]  |\n",
      "|6    |[2.0,1.0,3.0,1.0,1.0,8.0,6.0,6.0,6.0,6.0,5.0,9.0,1.0,7.0,5.0,10.0]    |\n",
      "|18   |[4.0,11.0,5.0,8.0,3.0,8.0,8.0,6.0,9.0,5.0,6.0,6.0,0.0,8.0,9.0,7.0]    |\n",
      "|1    |[4.0,2.0,5.0,4.0,4.0,8.0,7.0,6.0,6.0,7.0,6.0,6.0,2.0,8.0,7.0,10.0]    |\n",
      "|0    |[1.0,1.0,3.0,2.0,1.0,8.0,2.0,2.0,2.0,8.0,2.0,8.0,1.0,6.0,2.0,7.0]     |\n",
      "|9    |[2.0,2.0,4.0,4.0,2.0,10.0,6.0,2.0,6.0,12.0,4.0,8.0,1.0,6.0,1.0,7.0]   |\n",
      "|12   |[11.0,15.0,13.0,9.0,7.0,13.0,2.0,6.0,2.0,12.0,1.0,9.0,8.0,1.0,1.0,8.0]|\n",
      "+-----+----------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (3) Load the Letter Recognition Dataset (in CSV format with pre-defined label and features columns)\n",
    "# (3.1) Create Feature Vectors from the 16 features\n",
    "# (3.2) Rename the 'lettr' column to 'label' which is a number representing one of the 26 characters in the English alphabet\n",
    "\n",
    "letter_recognition_df = sqlContext.read.format('com.databricks.spark.csv').options(header = 'true', inferschema = 'true').load('/data/workspaces/jillur.quddus/jupyter/notebooks/Machine-Learning-with-Apache-Spark-QuickStart-Guide/chapter07/data/ocr-data/letter-recognition.csv')\n",
    "feature_columns = ['x-box','y-box','width','high','onpix','x-bar','y-bar','x2bar','y2bar','xybar','x2ybr','xy2br','x-ege','xegvy','y-ege','yegvx']\n",
    "vector_assembler = VectorAssembler(inputCols = feature_columns, outputCol = 'features')\n",
    "vectorised_df = vector_assembler.transform(letter_recognition_df).withColumnRenamed('lettr', 'label').select('label', 'features')\n",
    "vectorised_df.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14927, 5073)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (4) Split the Featurised DataFrame into a Training DataFrame and a Test DataFrame\n",
    "train_df, test_df = vectorised_df.randomSplit([0.75, 0.25], seed=12345)\n",
    "train_df.count(), test_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (5) Specify the layers for our Neural Network\n",
    "# (5.1) The 1st element in this list represents the size of the Input Layer. In our case, we have 16 features\n",
    "# (5.2) The next elements in the list represent the sizes of the intermediate Hidden Layers, in our case 8 and 4\n",
    "# (5.3) The final element in this list represents the size of the Output. In our case, we have 26 classes\n",
    "layers = [16, 8, 4, 26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (6) Train a Multilayer Perceptron Classifier using our list representing our layers from input to output layers\n",
    "multilayer_perceptron_classifier = MultilayerPerceptronClassifier(maxIter=100, layers=layers, blockSize=128, seed=1234)\n",
    "multilayer_perceptron_classifier_model = multilayer_perceptron_classifier.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST DATASET PREDICTIONS AGAINST ACTUAL LABEL: \n",
      "+-----+--------------------+--------------------+----------+\n",
      "|label|            features|         probability|prediction|\n",
      "+-----+--------------------+--------------------+----------+\n",
      "|    0|[1.0,0.0,2.0,0.0,...|[0.62605849526384...|       0.0|\n",
      "|    0|[1.0,0.0,2.0,0.0,...|[0.62875656935176...|       0.0|\n",
      "|    0|[1.0,0.0,2.0,0.0,...|[0.62875656935176...|       0.0|\n",
      "|    0|[1.0,0.0,2.0,0.0,...|[0.62836652229708...|       0.0|\n",
      "|    0|[1.0,0.0,2.0,0.0,...|[0.62875739589563...|       0.0|\n",
      "|    0|[1.0,0.0,2.0,0.0,...|[0.62875739589563...|       0.0|\n",
      "|    0|[1.0,1.0,2.0,2.0,...|[0.61675544434183...|       0.0|\n",
      "|    0|[1.0,3.0,2.0,1.0,...|[0.62709338540423...|       0.0|\n",
      "|    0|[1.0,3.0,2.0,1.0,...|[0.62873649217115...|       0.0|\n",
      "|    0|[1.0,3.0,2.0,2.0,...|[0.62874868432571...|       0.0|\n",
      "|    0|[1.0,3.0,3.0,2.0,...|[0.62144842233237...|       0.0|\n",
      "|    0|[2.0,0.0,3.0,1.0,...|[0.62875662456358...|       0.0|\n",
      "|    0|[2.0,1.0,3.0,2.0,...|[0.62644314912701...|       0.0|\n",
      "|    0|[2.0,1.0,4.0,2.0,...|[0.45427603505972...|       0.0|\n",
      "|    0|[2.0,1.0,4.0,2.0,...|[0.62709073401231...|       0.0|\n",
      "|    0|[2.0,1.0,4.0,2.0,...|[0.62859575468493...|       0.0|\n",
      "|    0|[2.0,1.0,4.0,2.0,...|[0.62870552032319...|       0.0|\n",
      "|    0|[2.0,1.0,4.0,3.0,...|[0.60252587473084...|       0.0|\n",
      "|    0|[2.0,1.0,4.0,3.0,...|[0.62870054886389...|       0.0|\n",
      "|    0|[2.0,2.0,4.0,3.0,...|[0.62869704205247...|       0.0|\n",
      "+-----+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (7) Apply the Trained Multilayer Perceptron Classifier Model to the Test DataFrame to make predictions\n",
    "test_predictions_df = multilayer_perceptron_classifier_model.transform(test_df)\n",
    "print(\"TEST DATASET PREDICTIONS AGAINST ACTUAL LABEL: \")\n",
    "test_predictions_df.select(\"label\", \"features\", \"probability\", \"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test Dataset = 0.339641\n",
      "Precision on Test Dataset = 0.313333\n",
      "Recall on Test Dataset = 0.339641\n"
     ]
    }
   ],
   "source": [
    "# (8) Compute the accuracy of our Trained Multilayer Perceptron Classifier Model on the Test DataFrame\n",
    "prediction_and_labels = test_predictions_df.select(\"prediction\", \"label\")\n",
    "accuracy_evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "precision_evaluator = MulticlassClassificationEvaluator(metricName=\"weightedPrecision\")\n",
    "recall_evaluator = MulticlassClassificationEvaluator(metricName=\"weightedRecall\")\n",
    "print(\"Accuracy on Test Dataset = %g\" % accuracy_evaluator.evaluate(prediction_and_labels))\n",
    "print(\"Precision on Test Dataset = %g\" % precision_evaluator.evaluate(prediction_and_labels))\n",
    "print(\"Recall on Test Dataset = %g\" % recall_evaluator.evaluate(prediction_and_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Accuracy on Test Dataset = 0.71575\n"
     ]
    }
   ],
   "source": [
    "# (9) To improve the accuracy of our model, let us increase the size of the Hidden Layers\n",
    "new_layers = [16, 16, 12, 26]\n",
    "new_multilayer_perceptron_classifier = MultilayerPerceptronClassifier(maxIter=400, layers=new_layers, blockSize=128, seed=1234)\n",
    "new_multilayer_perceptron_classifier_model = new_multilayer_perceptron_classifier.fit(train_df)\n",
    "new_test_predictions_df = new_multilayer_perceptron_classifier_model.transform(test_df)\n",
    "print(\"New Accuracy on Test Dataset = %g\" % accuracy_evaluator.evaluate(new_test_predictions_df.select(\"prediction\", \"label\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (10) Stop the Spark Context\n",
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
